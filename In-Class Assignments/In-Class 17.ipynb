{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1388308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libaries\n",
    "\n",
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "import cost_function as cf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e5046d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>6</td>\n",
       "      <td>239</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4</td>\n",
       "      <td>254</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5</td>\n",
       "      <td>253</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>management</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.92             0.95               6                   239   \n",
       "1                0.88             0.89               4                   254   \n",
       "2                0.66             0.93               5                   253   \n",
       "3                0.46             0.45               2                   172   \n",
       "4                0.88             0.75               5                   152   \n",
       "\n",
       "   time_spend_company  Work_accident  promotion_last_5years        sales  \\\n",
       "0                   4              0                      0        sales   \n",
       "1                   5              0                      0        sales   \n",
       "2                   5              0                      0  product_mng   \n",
       "3                   2              1                      0   management   \n",
       "4                   3              0                      0           hr   \n",
       "\n",
       "   salary  left  \n",
       "0  medium     0  \n",
       "1     low     1  \n",
       "2     low     1  \n",
       "3     low     0  \n",
       "4    high     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Using the pandas library to read the csv data files and create three data-frames called train,\n",
    "## validation and test, respectively.\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-448-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file\n",
    "file_key = 'turnover_train.csv'\n",
    "file_key2 = 'turnover_val.csv'\n",
    "file_key3 = 'turnover_test.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "bucket_object3 = bucket.Object(file_key3)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "file_object3 = bucket_object3.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "file_content_stream3 = file_object3.get('Body')\n",
    "\n",
    "train = pd.read_csv(file_content_stream)\n",
    "val = pd.read_csv(file_content_stream2)\n",
    "test = pd.read_csv(file_content_stream3)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ece17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Changing sales and salary from labels to dummy variables\n",
    "\n",
    "## Sales\n",
    "train = pd.concat([train.drop(columns = ['sales']), pd.get_dummies(train['sales'])], axis = 1)\n",
    "val = pd.concat([val.drop(columns = ['sales']), pd.get_dummies(val['sales'])], axis = 1)\n",
    "test = pd.concat([test.drop(columns = ['sales']), pd.get_dummies(test['sales'])], axis = 1)\n",
    "\n",
    "## Salary\n",
    "train = pd.concat([train.drop(columns = ['salary']), pd.get_dummies(train['salary'])], axis = 1)\n",
    "val = pd.concat([val.drop(columns = ['salary']), pd.get_dummies(val['salary'])], axis = 1)\n",
    "test = pd.concat([test.drop(columns = ['salary']), pd.get_dummies(test['salary'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f91ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Engineering the interactions/features from In-Class assignment 9 (the ones from the decision tree)\n",
    "\n",
    "train['Interaction_1'] = np.where((train['satisfaction_level'] <= 0.465) & (train['number_project'] <= 2.5) & \n",
    "                                     (train['last_evaluation'] <= 0.575), 1, 0)\n",
    "val['Interaction_1'] = np.where((val['satisfaction_level'] <= 0.465) & (val['number_project'] <= 2.5) & \n",
    "                                     (val['last_evaluation'] <= 0.575), 1, 0)\n",
    "test['Interaction_1'] = np.where((test['satisfaction_level'] <= 0.465) & (test['number_project'] <= 2.5) & \n",
    "                                     (test['last_evaluation'] <= 0.575), 1, 0)\n",
    "\n",
    "train['Interaction_2'] = np.where((train['satisfaction_level'] <= 0.465) & (train['number_project'] > 2.5) & \n",
    "                                     (train['satisfaction_level'] <= 0.115), 1, 0)\n",
    "val['Interaction_2'] = np.where((val['satisfaction_level'] <= 0.465) & (val['number_project'] > 2.5) & \n",
    "                                     (val['satisfaction_level'] <= 0.115), 1, 0)\n",
    "test['Interaction_2'] = np.where((test['satisfaction_level'] <= 0.465) & (test['number_project'] > 2.5) & \n",
    "                                     (test['satisfaction_level'] <= 0.115), 1, 0)\n",
    "\n",
    "train['Interaction_3'] = np.where((train['satisfaction_level'] > 0.465) & (train['time_spend_company'] <= 4.5) & \n",
    "                                     (train['average_montly_hours'] <= 290.5), 1, 0)\n",
    "val['Interaction_3'] = np.where((val['satisfaction_level'] > 0.465) & (val['time_spend_company'] <= 4.5) & \n",
    "                                     (val['average_montly_hours'] <= 290.5), 1, 0)\n",
    "test['Interaction_3'] = np.where((test['satisfaction_level'] > 0.465) & (test['time_spend_company'] <= 4.5) & \n",
    "                                     (test['average_montly_hours'] <= 290.5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dccff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "\n",
    "X_train = train[['Interaction_3', 'Interaction_1', 'satisfaction_level', 'time_spend_company', 'number_project']]\n",
    "Y_train = train['left']\n",
    "\n",
    "X_val = val[['Interaction_3', 'Interaction_1', 'satisfaction_level', 'time_spend_company', 'number_project']]\n",
    "Y_val = val['left']\n",
    "\n",
    "X_test = test[['Interaction_3', 'Interaction_1', 'satisfaction_level', 'time_spend_company', 'number_project']]\n",
    "Y_test = test['left']\n",
    "\n",
    "## Scaling the input data\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a1dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Using train data-frame and the top 5 features to perform a hyper-tuning job on the Random Forest model using the \n",
    "## GridSearchCV function \n",
    "\n",
    "## Defining the parameter dictionary\n",
    "rf_param_grid = {'n_estimators': [100, 300, 500], 'min_samples_split': [10, 15], 'min_samples_leaf': [5, 7], 'max_depth' : [3, 5, 7]}\n",
    "\n",
    "## Defining the custom scorer\n",
    "my_score_function = make_scorer(cf.cost_function, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "## Running GridSearchCV with 3 folds and the customized cost function\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = my_score_function, n_jobs = -1).fit(X_train, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "rf_md = rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc66f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1130   13]\n",
      " [  28  329]]\n",
      "\n",
      "The cost of the RF model is: 109500\n"
     ]
    }
   ],
   "source": [
    "## Using the optimal model to predict the likelihood of left on the validation and test data-frames\n",
    "rf_val_pred = rf_md.predict_proba(X_val)[:, 1]\n",
    "rf_test_pred = rf_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Finding the optimal cutoff value by comparing the likelihoods of left in validation and the actual left values in \n",
    "## the validation\n",
    "opt_cutoff = cf.cost_function_cutoff(Y_val, rf_val_pred)\n",
    "\n",
    "## Use this cutoff to change the likelihoods of left in the test data-frame to label\n",
    "rf_labels = np.where(rf_test_pred < opt_cutoff, 0, 1)\n",
    "\n",
    "## Compute the cost of this prediction on the test data-frame\n",
    "X = confusion_matrix(Y_test, rf_labels)\n",
    "print(X)\n",
    "print('\\nThe cost of the RF model is:', -1500*X[1,0] - 1000*X[0, 1] + 500*X[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8541bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Using train data-frame and the top 5 features to perform a hyper-tuning job on the SVM model using the \n",
    "## GridSearchCV function \n",
    "\n",
    "## Defining the parameter dictionary\n",
    "SVM_param_grid = {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "## Running GridSearchCV with 3 folds and the customized cost function\n",
    "svm_grid_search = GridSearchCV(SVC(probability = True), SVM_param_grid, cv = 3, scoring = my_score_function, n_jobs = -1).fit(X_train, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "svm_md = svm_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4dc563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1121   22]\n",
      " [  31  326]]\n",
      "\n",
      "The cost of the SVC model is: 94500\n"
     ]
    }
   ],
   "source": [
    "## Using the optimal model to predict the likelihood of left on the validation and test data-frames\n",
    "svm_val_pred = svm_md.predict_proba(X_val)[:, 1]\n",
    "svm_test_pred = svm_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Finding the optimal cutoff value by comparing the likelihoods of left in validation and the actual left values in \n",
    "## the validation\n",
    "opt_cutoff = cf.cost_function_cutoff(Y_val, svm_val_pred)\n",
    "\n",
    "## Use this cutoff to change the likelihoods of left in the test data-frame to label\n",
    "svm_labels = np.where(svm_test_pred < opt_cutoff, 0, 1)\n",
    "\n",
    "## Compute the cost of this prediction on the test data-frame\n",
    "X = confusion_matrix(Y_test, svm_labels)\n",
    "print(X)\n",
    "print('\\nThe cost of the SVC model is:', -1500*X[1,0] - 1000*X[0, 1] + 500*X[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfa1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the results from parts 5, 6, and 7, we would you use the Random Forest model to predict left \n",
    "## because of the better cost function result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
