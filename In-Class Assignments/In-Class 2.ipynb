{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca19ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.0-py3-none-any.whl (199 kB)\n",
      "     |████████████████████████████████| 199 kB 14.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "     |████████████████████████████████| 189 kB 78.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.1 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b249b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>AccountWeeks</th>\n",
       "      <th>ContractRenewal</th>\n",
       "      <th>DataPlan</th>\n",
       "      <th>DataUsage</th>\n",
       "      <th>CustServCalls</th>\n",
       "      <th>DayMins</th>\n",
       "      <th>DayCalls</th>\n",
       "      <th>MonthlyCharge</th>\n",
       "      <th>OverageFee</th>\n",
       "      <th>RoamMins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9.78</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.42</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  AccountWeeks  ContractRenewal  DataPlan  DataUsage  CustServCalls  \\\n",
       "0      0           128                1         1        2.7              1   \n",
       "1      0           107                1         1        3.7              1   \n",
       "2      0           137                1         0        0.0              0   \n",
       "3      0            84                0         0        0.0              2   \n",
       "4      0            75                0         0        0.0              3   \n",
       "\n",
       "   DayMins  DayCalls  MonthlyCharge  OverageFee  RoamMins  \n",
       "0    265.1       110           89.0        9.87      10.0  \n",
       "1    161.6       123           82.0        9.78      13.7  \n",
       "2    243.4       114           52.0        6.06      12.2  \n",
       "3    299.4        71           57.0        3.10       6.6  \n",
       "4    166.7       113           41.0        7.42      10.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, classification_report\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file\n",
    "file_key = 'telecom_churn.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## 1. Using the pandas library to read the csv data file and create a data-frame called churn_data\n",
    "\n",
    "churn_data = pd.read_csv(file_content_stream)\n",
    "\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67a46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Using AccountWeeks, ContractRenewal, CustServCalls, MonthlyCharge, and DayMins as the predictor variables, \n",
    "## and Churn as the target variable, splitting the data into two data-frames (taking into account the proportion \n",
    "## of 0s and 1s): train (80%) and test (20%).\n",
    "\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = churn_data[['AccountWeeks', 'ContractRenewal', 'CustServCalls', 'MonthlyCharge', 'DayMins']]\n",
    "Y = churn_data['Churn']\n",
    "\n",
    "## Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54880076",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Creating a synthetic training dataset, called them X_over and Y_over by running over-sampling on the train dataset\n",
    "\n",
    "X_over, Y_over = RandomOverSampler().fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c659f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89       570\n",
      "           1       0.44      0.75      0.56        97\n",
      "\n",
      "    accuracy                           0.82       667\n",
      "   macro avg       0.70      0.79      0.72       667\n",
      "weighted avg       0.88      0.82      0.84       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 4. Using X_over and Y_over datasets to build a random forest classification model with 500 trees\n",
    "## and the maximum depth of each tree equal to 3\n",
    "\n",
    "## Building the model\n",
    "rf_md = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X_over, Y_over)\n",
    "\n",
    "## Predicting on the test set\n",
    "rf_preds = rf_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Estimate the cutoff value with the ROC-curve\n",
    "fpr, tpr, threshold = roc_curve(Y_test, rf_preds)\n",
    "\n",
    "## Creating a data frame to store ROC-Curve results\n",
    "cutoffs = pd.DataFrame({'False_Positive': fpr, 'True_Positive': tpr, 'Cutoff': threshold})\n",
    "\n",
    "## Calculating the Euclidean distance between each point and our optimal model (fpr = 0, tpr = 1)\n",
    "cutoffs['True_Positive_Minus_1'] = cutoffs['True_Positive'] - 1\n",
    "cutoffs['Distance'] = np.sqrt(cutoffs['False_Positive']**2 + cutoffs['True_Positive_Minus_1']**2)\n",
    "\n",
    "## Sorting the data frame based on Euclidean distance\n",
    "cutoffs = cutoffs.sort_values('Distance', ascending = True).reset_index(drop = True)\n",
    "\n",
    "## Changing likelihoods to labels\n",
    "rf_preds = np.where(rf_preds < cutoffs['Cutoff'][0], 0, 1)\n",
    "\n",
    "## Using the optimal cutoff value to create the classification report\n",
    "print(classification_report(Y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16c5cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       570\n",
      "           1       0.54      0.74      0.62        97\n",
      "\n",
      "    accuracy                           0.87       667\n",
      "   macro avg       0.75      0.82      0.77       667\n",
      "weighted avg       0.89      0.87      0.88       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5. Using X_over and Y_over datasets to build a ada-boost classification model with 500 trees,\n",
    "## the maximum depth of each tree equal to 3, and learning rate equal to 0.01\n",
    "\n",
    "## Building the model\n",
    "ada_md = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), \n",
    "                            n_estimators = 500, learning_rate = 0.01).fit(X_over, Y_over)\n",
    "\n",
    "## Predicting on the test set\n",
    "ada_preds = ada_md.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Estimate the cutoff value with the ROC-curve\n",
    "fpr, tpr, threshold = roc_curve(Y_test, ada_preds)\n",
    "\n",
    "## Creating a data frame to store ROC-Curve results\n",
    "cutoffs = pd.DataFrame({'False_Positive': fpr, 'True_Positive': tpr, 'Cutoff': threshold})\n",
    "\n",
    "## Calculating the Euclidean distance between each point and our optimal model (0,1)\n",
    "cutoffs['True_Positive_Minus_1'] = cutoffs['True_Positive'] - 1\n",
    "cutoffs['Distance'] = np.sqrt(cutoffs['False_Positive']**2 + cutoffs['True_Positive_Minus_1']**2)\n",
    "\n",
    "## Sorting the data frame based on Euclidean distance\n",
    "cutoffs = cutoffs.sort_values('Distance', ascending = True).reset_index(drop = True)\n",
    "\n",
    "## Changing likelihoods to labels\n",
    "ada_preds_label = np.where(ada_preds < cutoffs['Cutoff'][0], 0, 1)\n",
    "\n",
    "## Using the optimal cutoff value to create the classification report\n",
    "print(classification_report(Y_test, ada_preds_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Using the results from part 4 and 5, we would use the AdaBoost Classification model to \n",
    "## predict customer churn because it shows higher precision testing scores for the minority class\n",
    "## and right around the same recall testing score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
