{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43617d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libaries\n",
    "\n",
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69b8d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Using the pandas library to read the csv data file and create a data-frames called insurance\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-448-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file\n",
    "file_key = 'insurance.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "insurance = pd.read_csv(file_content_stream)\n",
    "\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "038c8f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>northeast</th>\n",
       "      <th>northwest</th>\n",
       "      <th>southeast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker     region      charges  northeast  \\\n",
       "0   19    0  27.900         0       1  southwest  16884.92400          0   \n",
       "1   18    1  33.770         1       0  southeast   1725.55230          0   \n",
       "2   28    1  33.000         3       0  southeast   4449.46200          0   \n",
       "3   33    1  22.705         0       0  northwest  21984.47061          0   \n",
       "4   32    1  28.880         0       0  northwest   3866.85520          0   \n",
       "\n",
       "   northwest  southeast  \n",
       "0          0          0  \n",
       "1          0          1  \n",
       "2          0          1  \n",
       "3          1          0  \n",
       "4          1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. Changing sex, smoker and region from labels to dummy variables.\n",
    "\n",
    "## Changing labels to numbers\n",
    "insurance['sex'] = np.where(insurance['sex'] == 'female', 0, 1)\n",
    "insurance['smoker'] = np.where(insurance['smoker'] == 'no', 0, 1)\n",
    "\n",
    "## Extracting region dummies\n",
    "region_dummies = pd.get_dummies(insurance['region']).iloc[:, 0:3]\n",
    "\n",
    "## Appending dummies\n",
    "insurance = pd.concat([insurance, region_dummies], axis = 1)\n",
    "\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb522a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.  Engineer the interactions/features from Chapter 4 lecture notes (the ones from the decision tree)\n",
    "\n",
    "## Feature engineering:\n",
    "insurance['interaction_1'] = np.where((insurance['smoker'] == 0) & (insurance['age'] <= 32.5), 1, 0)\n",
    "\n",
    "insurance['interaction_2'] = np.where((insurance['smoker'] == 0) & (insurance['age'] > 32.5) & (insurance['age'] <= 44.5), 1, 0)\n",
    "\n",
    "insurance['interaction_3'] = np.where((insurance['smoker'] == 0) & (insurance['age'] > 44.5) & (insurance['age'] < 51.5), 1, 0)\n",
    "\n",
    "insurance['interaction_4'] = np.where((insurance['smoker'] == 0) & (insurance['age'] > 51.5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df659a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Based on the feature selection analysis shown in Chapter 4, it seems that age, bmi, children, smoker, and interaction 4 \n",
    "## are the top 5 important variables. Using the top variables as input variables and charges as the target variable to split the \n",
    "## data into three datasets: train (80%), validation (10%) and test (10%)\n",
    "\n",
    "## Defining input and target variables\n",
    "X = insurance[['age','bmi', 'children', 'smoker', 'interaction_4']]\n",
    "Y = insurance['charges']\n",
    "\n",
    "## Splitting the data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size = 0.5)\n",
    "\n",
    "## Changing the scale of the inputs\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f035d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination: {'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 15, 'n_estimators': 100}\n",
      "\n",
      "Mean Square Error on the validation set: 14338492\n",
      "Mean Square Error on the testing set: 23572859\n"
     ]
    }
   ],
   "source": [
    "## 5. Using train data-frame and the top 5 features to perform a hyper-tuning job on the random forest model using the \n",
    "## GridSearchCV function and the following dictionary:\n",
    "\n",
    "RF_param_grid = {'n_estimators': [100, 300, 500], 'min_samples_split': [10, 15], 'min_samples_leaf': [5, 7], 'max_depth': [3, 5, 7]}\n",
    "\n",
    "## Running GridSearchCV with three folds\n",
    "rf_grid_search = GridSearchCV(RandomForestRegressor(), RF_param_grid, cv = 3, scoring = 'neg_mean_squared_error', \n",
    "                             n_jobs = -1).fit(X_train, Y_train)\n",
    "\n",
    "## Printing the best hyper-parameters\n",
    "print('Best hyper-parameter combination:', rf_grid_search.best_params_)\n",
    "\n",
    "## Extracting the optimal model\n",
    "rf_md = rf_grid_search.best_estimator_\n",
    "\n",
    "## Using the optimal model to predict the charges on the validation and test set\n",
    "rf_val_preds = rf_md.predict(X_val)\n",
    "rf_test_preds = rf_md.predict(X_test)\n",
    "\n",
    "## Computing the mean squared error of the predictions \n",
    "rf_val_mse = mean_squared_error(Y_val, rf_val_preds)\n",
    "rf_test_mse = mean_squared_error(Y_test, rf_test_preds)\n",
    "\n",
    "print('\\nMean Square Error on the validation set:', round(rf_val_mse))\n",
    "print('Mean Square Error on the testing set:', round(rf_test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fa3bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination: {'C': 10, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      "Mean Square Error on the validation set: 80785897\n",
      "Mean Square Error on the testing set: 102938451\n"
     ]
    }
   ],
   "source": [
    "## 6. Using train data-frame and the top 5 features to perform a hyper-tuning job on the support vector machine model using the \n",
    "## GridSearchCV function and the following dictionary:\n",
    "\n",
    "SVM_param_grid = {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "## Running GridSearchCV with three folds\n",
    "svm_grid_search = GridSearchCV(SVR(), SVM_param_grid, cv = 3, scoring = 'neg_mean_squared_error', \n",
    "                             n_jobs = -1).fit(X_train, Y_train)\n",
    "\n",
    "## Printing the best hyper-parameters\n",
    "print('Best hyper-parameter combination:',svm_grid_search.best_params_)\n",
    "\n",
    "## Extracting the optimal model\n",
    "svm_md = svm_grid_search.best_estimator_\n",
    "\n",
    "## Using the optimal model to predict the charges on the validation and test set\n",
    "svm_val_preds = svm_md.predict(X_val)\n",
    "svm_test_preds = svm_md.predict(X_test)\n",
    "\n",
    "## Computing the mean squared error of the predictions \n",
    "svm_val_mse = mean_squared_error(Y_val, svm_val_preds)\n",
    "svm_test_mse = mean_squared_error(Y_test, svm_test_preds)\n",
    "\n",
    "print('\\nMean Square Error on the validation set:', round(svm_val_mse))\n",
    "print('Mean Square Error on the testing set:', round(svm_test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cee6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameter combination: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Mean Square Error on the testing set using the ensemble model: 27002154\n"
     ]
    }
   ],
   "source": [
    "## 7. Using the predictions on the validation data-frame from parts 5 & 6 to build an ensemble model (using the random forest model)\n",
    "\n",
    "## Building the ensemble data set\n",
    "X_ensemble = pd.concat([pd.DataFrame(rf_val_preds), pd.DataFrame(svm_val_preds)], axis = 1)\n",
    "\n",
    "## Performing a hyper-parameter tuning job on the ensemble model (using the same set of hyper-parameters from part 5)\n",
    "ensemble_grid_search = GridSearchCV(RandomForestRegressor(), RF_param_grid, cv = 3, scoring = 'neg_mean_squared_error', \n",
    "                             n_jobs = -1).fit(X_ensemble, Y_val)\n",
    "\n",
    "## Printing the best hyper-parameters\n",
    "print('Best hyper-parameter combination:', ensemble_grid_search.best_params_)\n",
    "\n",
    "## Identifying the model that produces the minimum squared error\n",
    "rf_md_ensemble = ensemble_grid_search.best_estimator_\n",
    "\n",
    "## Using the ensemble model to predict charges on the test data-frame\n",
    "rf_ensemble_preds = rf_md_ensemble.predict(pd.concat([pd.DataFrame(rf_test_preds), pd.DataFrame(svm_test_preds)], axis = 1))\n",
    "\n",
    "## Computing the mean squared error of the predictions on the test data-frame\n",
    "rf_ensemble_mse = mean_squared_error(Y_test, rf_ensemble_preds)\n",
    "print('\\nMean Square Error on the testing set using the ensemble model:', round(rf_ensemble_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05739e",
   "metadata": {},
   "source": [
    "## 8. Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ced10",
   "metadata": {},
   "source": [
    "Based on the results from parts 5, 6, and 7, we would use the Random Forest Classifier model with the following hyper-parameters: 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 15, 'n_estimators': 100. This model had a slightly better MSE than the ensemble model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
