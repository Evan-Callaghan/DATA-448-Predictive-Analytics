{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc855a2",
   "metadata": {},
   "source": [
    "# Predictive Analtics Exam 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15312940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba91ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d62413",
   "metadata": {},
   "source": [
    "### 15. Considering the train.csv and test.csv data files containing information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. The goal is to predict default payment next month on the test.csv data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462d49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries\n",
    "\n",
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import precision_recall_cutoff_exam2 as prc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f809209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55773</td>\n",
       "      <td>55917</td>\n",
       "      <td>51389</td>\n",
       "      <td>48272</td>\n",
       "      <td>49478</td>\n",
       "      <td>51242</td>\n",
       "      <td>3028</td>\n",
       "      <td>3023</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>38662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>140</td>\n",
       "      <td>3230</td>\n",
       "      <td>3011</td>\n",
       "      <td>1964</td>\n",
       "      <td>1883</td>\n",
       "      <td>1538</td>\n",
       "      <td>3230</td>\n",
       "      <td>3011</td>\n",
       "      <td>1964</td>\n",
       "      <td>1883</td>\n",
       "      <td>1538</td>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59710</td>\n",
       "      <td>49986</td>\n",
       "      <td>104390</td>\n",
       "      <td>94856</td>\n",
       "      <td>86461</td>\n",
       "      <td>83650</td>\n",
       "      <td>1808</td>\n",
       "      <td>69563</td>\n",
       "      <td>2891</td>\n",
       "      <td>2689</td>\n",
       "      <td>3012</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280913</td>\n",
       "      <td>283222</td>\n",
       "      <td>273160</td>\n",
       "      <td>257689</td>\n",
       "      <td>193231</td>\n",
       "      <td>191143</td>\n",
       "      <td>11052</td>\n",
       "      <td>9563</td>\n",
       "      <td>15017</td>\n",
       "      <td>5374</td>\n",
       "      <td>5420</td>\n",
       "      <td>6021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1512</td>\n",
       "      <td>2458</td>\n",
       "      <td>664</td>\n",
       "      <td>1814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>664</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0     400000    1          1         2   32      0      0      0      0   \n",
       "1     120000    2          2         2   30     -1     -1     -1     -1   \n",
       "2     270000    2          2         2   32      0      0      0      0   \n",
       "3     280000    2          2         1   27      0      0      0      0   \n",
       "4      30000    2          1         2   27      0      0     -1      0   \n",
       "\n",
       "   PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0      0      0      55773      55917      51389      48272      49478   \n",
       "1     -1     -1        140       3230       3011       1964       1883   \n",
       "2      0      0      59710      49986     104390      94856      86461   \n",
       "3      0      0     280913     283222     273160     257689     193231   \n",
       "4      0     -2       1512       2458        664       1814          0   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0      51242      3028      3023      3000      3000      3000     38662   \n",
       "1       1538      3230      3011      1964      1883      1538      1911   \n",
       "2      83650      1808     69563      2891      2689      3012      2771   \n",
       "3     191143     11052      9563     15017      5374      5420      6021   \n",
       "4          0      1000       664      1500         0         0         0   \n",
       "\n",
       "   default payment next month  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a) Using the pandas library to read the train.csv and test.csv data files and create two data-frames called train and test\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-448-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key = 'train(1).csv'\n",
    "file_key2 = 'test(1).csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "train = pd.read_csv(file_content_stream)\n",
    "test = pd.read_csv(file_content_stream2)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbfa2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Engineering features from Exam 1\n",
    "\n",
    "## Train set:\n",
    "\n",
    "## Most common repayment status\n",
    "train['Most_Common'] = np.nan\n",
    "for i in range(0, train.shape[0]):\n",
    "    train.at[i, 'Most_Common'] = train[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].loc[i].mode()[0]\n",
    "\n",
    "## From plot tree:\n",
    "train['Tree2'] = np.where((train['PAY_0'] <= 1.5) & (train['PAY_2'] <= 1.5) & (train['PAY_AMT3'] > 395.0), 1, 0)\n",
    "train['Tree6'] = np.where((train['PAY_0'] > 1.5) & (train['PAY_6'] <= 1.0) & (train['BILL_AMT1'] > 649.5), 1, 0)\n",
    "train['Tree7'] = np.where((train['PAY_0'] > 1.5) & (train['PAY_6'] > 1.0) & (train['PAY_AMT3'] <= 14177.0), 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "## Test set:\n",
    "\n",
    "## Most common repayment status\n",
    "test['Most_Common'] = np.nan\n",
    "for i in range(0, test.shape[0]):\n",
    "    test.at[i, 'Most_Common'] = test[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].loc[i].mode()[0]\n",
    "\n",
    "## From plot tree:\n",
    "test['Tree2'] = np.where((test['PAY_0'] <= 1.5) & (test['PAY_2'] <= 1.5) & (test['PAY_AMT3'] > 395.0), 1, 0)\n",
    "test['Tree6'] = np.where((test['PAY_0'] > 1.5) & (test['PAY_6'] <= 1.0) & (test['BILL_AMT1'] > 649.5), 1, 0)\n",
    "test['Tree7'] = np.where((test['PAY_0'] > 1.5) & (test['PAY_6'] > 1.0) & (test['PAY_AMT3'] <= 14177.0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7dd4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## b) Splitting the train data-frame intro training (80%) and validation (20%) (taking into account the proportions of 0s and 1s)\n",
    "\n",
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['default payment next month'])\n",
    "Y = train['default payment next month']\n",
    "\n",
    "## Splitting the data\n",
    "X_training, X_validation, Y_training, Y_validation = train_test_split(X, Y, test_size = 0.2, stratify = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48037739",
   "metadata": {},
   "source": [
    "#### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562d6e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff of Random Forest Model: 0.284\n",
      "\n",
      "F1-Score of Random Forest Model: 55.26 %\n"
     ]
    }
   ],
   "source": [
    "## c) Using the top 7 variables from Exercise 15 part (e) in Exam 1 to  build a model on the training data-frame\n",
    "\n",
    "## Redefining the input and target variables\n",
    "X_training = X_training[['PAY_0', 'PAY_2', 'Most_Common', 'Tree2', 'Tree6', 'PAY_3', 'Tree7']]\n",
    "X_validation = X_validation[['PAY_0', 'PAY_2', 'Most_Common', 'Tree2', 'Tree6', 'PAY_3', 'Tree7']]\n",
    "test = test[['PAY_0', 'PAY_2', 'Most_Common', 'Tree2', 'Tree6', 'PAY_3', 'Tree7']]\n",
    "\n",
    "## Building a Random Forest Model with default hyper-parameters\n",
    "rf_md = RandomForestClassifier().fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the validation set\n",
    "rf_preds = rf_md.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "## Extracting estimated labels using the PRC function\n",
    "rf_labels = prc.precision_recall_cutoff(Y_validation, rf_preds)\n",
    "\n",
    "## Extracting optimal cutoff using the PRC function\n",
    "rf_cutoff = prc.precision_recall_cutoff_cutoff(Y_validation, rf_preds)\n",
    "\n",
    "## Reporting the optimal cutoff value\n",
    "print('Optimal Cutoff of Random Forest Model:', round(rf_cutoff, 3))\n",
    "\n",
    "## Reporting the F1-Score of the model\n",
    "print('\\nF1-Score of Random Forest Model:', round(f1_score(Y_validation, rf_labels) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed0c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyper-parameters for Random Forest Model: \n",
      " {'max_depth': 3, 'min_samples_leaf': 10, 'min_samples_split': 15, 'n_estimators': 100}\n",
      "\n",
      "Optimal F1-Score:\n",
      " 0.48631723859203585\n"
     ]
    }
   ],
   "source": [
    "## Tuning the Random Forest model on the validation data-frame\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "rf_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [5, 10, 15], \n",
    "                  'min_samples_leaf': [5, 10, 15]}\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Optimal hyper-parameters for Random Forest Model: \\n', rf_grid_search.best_params_)\n",
    "print('\\nOptimal F1-Score:\\n', rf_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1019889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff of Random Forest Model: 0.228\n",
      "\n",
      "F1-Score of Random Forest Model: 55.52 %\n"
     ]
    }
   ],
   "source": [
    "## Building a Random Forest model with the optimal hyper-parameters\n",
    "rf_md = RandomForestClassifier(max_depth = 3, min_samples_leaf = 10, min_samples_split = 15, \n",
    "                               n_estimators = 100).fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the validation set\n",
    "rf_preds = rf_md.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "## Extracting estimated labels using the PRC function\n",
    "rf_labels = prc.precision_recall_cutoff(Y_validation, rf_preds)\n",
    "\n",
    "## Extracting optimal cutoff using the PRC function\n",
    "rf_cutoff = prc.precision_recall_cutoff_cutoff(Y_validation, rf_preds)\n",
    "\n",
    "## Reporting the optimal cutoff value\n",
    "print('Optimal Cutoff of Random Forest Model:', round(rf_cutoff, 3))\n",
    "\n",
    "## Reporting the F1-Score of the model\n",
    "print('\\nF1-Score of Random Forest Model:', round(f1_score(Y_validation, rf_labels) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1926a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, using the optimal model to predict the likelihood of default payment next month on the test\n",
    "\n",
    "rf_test_preds = rf_md.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a778d0",
   "metadata": {},
   "source": [
    "#### AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409d07b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff of AdaBoost Model: 0.496\n",
      "\n",
      "F1-Score of AdaBoost Model: 55.2 %\n"
     ]
    }
   ],
   "source": [
    "## d) Using the top 7 variables from Exercise 15 part (e) in Exam 1 to  build a model on the training data-frame\n",
    "\n",
    "## Building anAdaBoost Model with default hyper-parameters\n",
    "ada_md = AdaBoostClassifier().fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the validation set\n",
    "ada_preds = ada_md.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "## Extracting estimated labels using the PRC function\n",
    "ada_labels = prc.precision_recall_cutoff(Y_validation, ada_preds)\n",
    "\n",
    "## Extracting optimal cutoff using the PRC function\n",
    "ada_cutoff = prc.precision_recall_cutoff_cutoff(Y_validation, ada_preds)\n",
    "\n",
    "## Reporting the optimal cutoff value\n",
    "print('Optimal Cutoff of AdaBoost Model:', round(ada_cutoff, 3))\n",
    "\n",
    "## Reporting the F1-Score of the model\n",
    "print('\\nF1-Score of AdaBoost Model:', round(f1_score(Y_validation, ada_labels) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca26071",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tuning the AdaBoost model on the validation data-frame\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "ada_param_grid = {'n_estimators': [100, 300, 500], 'base_estimator__min_samples_split': [5, 10, 15], \n",
    "                  'base_estimator__min_samples_leaf': [5, 10, 15], 'base_estimator__max_depth': [3, 5, 7], \n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "ada_grid_search = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_param_grid, \n",
    "                               cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Optimal hyper-parameters for AdaBoost Model: \\n', ada_grid_search.best_params_)\n",
    "print('\\nOptimal F1-Score:\\n', ada_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a AdaBoost model with the optimal hyper-parameters\n",
    "ada_md = AdaBoostClassifier(max_depth = 3, min_samples_leaf = 10, min_samples_split = 15, \n",
    "                               n_estimators = 100).fit(X_training, Y_training)\n",
    "\n",
    "## Predicting on the validation set\n",
    "ada_preds = ada_md.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "## Extracting estimated labels using the PRC function\n",
    "ada_labels = prc.precision_recall_cutoff(Y_validation, ada_preds)\n",
    "\n",
    "## Extracting optimal cutoff using the PRC function\n",
    "ada_cutoff = prc.precision_recall_cutoff_cutoff(Y_validation, ada_preds)\n",
    "\n",
    "## Reporting the optimal cutoff value\n",
    "print('Optimal Cutoff of AdaBoost Model:', round(ada_cutoff, 3))\n",
    "\n",
    "## Reporting the F1-Score of the model\n",
    "print('\\nF1-Score of AdaBoost Model:', round(f1_score(Y_validation, ada_labels) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0dbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally, using the optimal model to predict the likelihood of default payment next month on the test\n",
    "\n",
    "ada_test_preds = ada_md.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717a7bd",
   "metadata": {},
   "source": [
    "#### XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7aad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046276b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77737e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6421fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fd5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use the provided precision recall cutoff.py (posted under the Exam\n",
    "2 link) file to estimate the optimal cutoff value. Report the F1-score of the model.\n",
    "Finally, use the optimal model to predict the likelihood of default payment next\n",
    "month on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model: RandomForestClassifier\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "rf_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [5, 10, 15], \n",
    "                  'min_samples_leaf': [5, 10, 15]}\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Optimal hyper-parameters for Random Forest Model: \\n', rf_grid_search.best_params_)\n",
    "print('\\nOptimal F1-Score:\\n', rf_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
