{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59bbf12",
   "metadata": {},
   "source": [
    "# Homework Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e3e11",
   "metadata": {},
   "source": [
    "### Topics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988b72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import dmc_cost_function\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c553c8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0           5                    1054       54.70              7   \n",
       "1           3                     108       27.36              5   \n",
       "2           3                    1516       62.16              3   \n",
       "3           6                    1791       92.31              8   \n",
       "4           5                     430       81.53              3   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "3                         4                      4                   0.016192   \n",
       "4                         7                      2                   0.062791   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  fraud  \n",
       "0        0.051898                  0.241379      0  \n",
       "1        0.253333                  0.357143      0  \n",
       "2        0.041003                  0.230769      0  \n",
       "3        0.051541                  0.275862      0  \n",
       "4        0.189605                  0.111111      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Using pandas to read the training and testing data files\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-448-bucket-callaghan'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "file_key = 'train.csv'\n",
    "file_key2 = 'test.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "train = pd.read_csv(file_content_stream, sep = '|')\n",
    "test = pd.read_csv(file_content_stream2, sep = '|')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f35bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating variables from previous homework assignments\n",
    "\n",
    "## Training set:\n",
    "\n",
    "## Variable 1 (from decision tree)\n",
    "train['Interaction_1'] = np.where((train['trustLevel'] <= 1.5) & (train['scannedLineItemsPerSecond'] <= 0.012) & \n",
    "                                  (train['lineItemVoids'] <= 10.5), 0, 1)\n",
    "## Variable 2 (from decision tree)\n",
    "train['Interaction_2'] = np.where((train['trustLevel'] <= 1.5) & (train['scannedLineItemsPerSecond'] > 0.012) & \n",
    "                                  (train['totalScanTimeInSeconds'] <= 895.0), 0, 1)\n",
    "## Variable 3 (from decision tree)\n",
    "train['Interaction_3'] = np.where((train['trustLevel'] > 1.5) & (train['grandTotal'] <= 99.145) & \n",
    "                                  train['trustLevel'] <= 2.5, 1, 0)\n",
    "## Variable 4 (from decision tree)\n",
    "train['Interaction_4'] = np.where((train['trustLevel'] > 1.5) & (train['grandTotal'] > 99.145) & \n",
    "                                  train['valuePerSecond'] <= 0.06, 1, 0)\n",
    "## Variable 5 - Low trustLevel (all frauds came from trustLevel = 1 or 2)\n",
    "train['lowTrust'] = np.where(train['trustLevel'] <= 2, 1, 0)\n",
    "\n",
    "## Variable 6 - Made a quantity modification\n",
    "train['madeModification'] = np.where(train['quantityModifications'] > 0, 1, 0)\n",
    "\n",
    "## Variable 7 - Attempted a scan without registration\n",
    "train['madeScansWithoutRegistration'] = np.where(train['scansWithoutRegistration'] > 0, 1, 0)\n",
    "\n",
    "## Variable 8 - High or low totalScanTimeInSeconds (huge differnece in mean and median values for fraud/not fraud in this field)\n",
    "train['lowTotalScanTime'] = np.where(train['totalScanTimeInSeconds'] < 1000, 1, 0)\n",
    "\n",
    "## Varibales from strong heredity principle\n",
    "train['Heredity_Feature_1'] = train['trustLevel'] * train['lowTrust']\n",
    "train['Heredity_Feature_2'] = train['trustLevel'] * train['scannedLineItemsPerSecond']\n",
    "train['Heredity_Feature_3'] = train['lowTrust'] * train['scannedLineItemsPerSecond']\n",
    "\n",
    "## Heredity_Feature_3: all observations less than 0.012 are not fraud in this tree\n",
    "train['New_Interaction_1'] = np.where(train['Heredity_Feature_3'] <= 0.012, 1, 0)\n",
    "\n",
    "## Lots of positove observations when Heredity_Feature_3 > 0.012, totalScanTimeInSeconds > 1298.0, and trustLevel <= 1.5\n",
    "train['New_Interaction_2'] = np.where((train['Heredity_Feature_3'] > 0.012) & (train['totalScanTimeInSeconds'] > 1298.0) \n",
    "                                      & (train['trustLevel'] < 1.5), 1, 0)\n",
    "\n",
    "## Mostly all negative observations when Heredity_Feature_3 > 0.012, totalScanTimeInSeconds <= 1298.0, and Heredity_Feature_1 > 0.119\n",
    "train['New_Interaction_3'] = np.where((train['Heredity_Feature_3'] > 0.012) & (train['totalScanTimeInSeconds'] <= 1298.0) \n",
    "                                      & (train['Heredity_Feature_1'] > 1.5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1374f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing set:\n",
    "\n",
    "## Variable 1\n",
    "test['Interaction_1'] = np.where((test['trustLevel'] <= 1.5) & (test['scannedLineItemsPerSecond'] <= 0.012) & \n",
    "                                  (test['lineItemVoids'] <= 10.5), 0, 1)\n",
    "## Variable 2\n",
    "test['Interaction_2'] = np.where((test['trustLevel'] <= 1.5) & (test['scannedLineItemsPerSecond'] > 0.012) & \n",
    "                                  (test['totalScanTimeInSeconds'] <= 895.0), 0, 1)\n",
    "## Variable 3\n",
    "test['Interaction_3'] = np.where((test['trustLevel'] > 1.5) & (test['grandTotal'] <= 99.145) & \n",
    "                                  test['trustLevel'] <= 2.5, 1, 0)\n",
    "## Variable 4\n",
    "test['Interaction_4'] = np.where((test['trustLevel'] > 1.5) & (test['grandTotal'] > 99.145) & \n",
    "                                  test['valuePerSecond'] <= 0.06, 1, 0)\n",
    "## Variable 5 - Low trustLevel\n",
    "test['lowTrust'] = np.where(test['trustLevel'] <= 2, 1, 0)\n",
    "\n",
    "## Variable 6 - Made a quantity modification\n",
    "test['madeModification'] = np.where(test['quantityModifications'] > 0, 1, 0)\n",
    "\n",
    "## Variable 7 - Attempted a scan without registration\n",
    "test['madeScansWithoutRegistration'] = np.where(test['scansWithoutRegistration'] > 0, 1, 0)\n",
    "\n",
    "## Variable 8 - High or low totalScanTimeInSeconds\n",
    "test['lowTotalScanTime'] = np.where(test['totalScanTimeInSeconds'] < 1000, 1, 0)\n",
    "\n",
    "## Varibales from strong heredity principle\n",
    "test['Heredity_Feature_1'] = test['trustLevel'] * test['lowTrust']\n",
    "test['Heredity_Feature_2'] = test['trustLevel'] * test['scannedLineItemsPerSecond']\n",
    "test['Heredity_Feature_3'] = test['lowTrust'] * test['scannedLineItemsPerSecond']\n",
    "\n",
    "test['New_Interaction_1'] = np.where(test['Heredity_Feature_3'] <= 0.012, 1, 0)\n",
    "\n",
    "test['New_Interaction_2'] = np.where((test['Heredity_Feature_3'] > 0.012) & (test['totalScanTimeInSeconds'] > 1298.0) \n",
    "                                      & (test['trustLevel'] < 1.5), 1, 0)\n",
    "\n",
    "test['New_Interaction_3'] = np.where((test['Heredity_Feature_3'] > 0.012) & (test['totalScanTimeInSeconds'] <= 1298.0) \n",
    "                                      & (test['Heredity_Feature_1'] > 1.5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5a14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the input and target variables\n",
    "X_train = train.drop(columns = ['fraud'])\n",
    "Y_train = train['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f99b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters for RandomForestClassifier with top-5 variables: \n",
      " {'max_depth': 7, 'min_samples_leaf': 15, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Best score:\n",
      " -16.666666666666668\n",
      "\n",
      "Best hyper-parameters for RandomForestClassifier with top-6 variables: \n",
      " {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "\n",
      "Best score:\n",
      " -26.666666666666668\n",
      "\n",
      "Best hyper-parameters for RandomForestClassifier with top-7 variables: \n",
      " {'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "\n",
      "Best score:\n",
      " -26.666666666666668\n"
     ]
    }
   ],
   "source": [
    "## 2.  Using the train data-frame (including the top 7 features from homework assignment 6) to do the following:\n",
    "\n",
    "## (i) Considering a model to predict fraud:\n",
    "## With the top 5 important features and using the GridSearchCV function with cv = 3 to run a hyper-parameter tuning procedure on the model\n",
    "## With the top 6 important features and using the GridSearchCV function with cv = 3 to run a hyper-parameter tuning procedure on the model\n",
    "## With the top 7 important features and using the GridSearchCV function with cv = 3 to run a hyper-parameter tuning procedure on the model\n",
    "\n",
    "## Evaluating the models on the associated cost function from the Data Mining Cup task site\n",
    "\n",
    "## Model: RandomForestClassifier\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "rf_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [5, 10, 15], \n",
    "                  'min_samples_leaf': [5, 10, 15]}\n",
    "\n",
    "## Defining the custom scorer\n",
    "my_scorer = make_scorer(dmc_cost_function.cost_function, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-5 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', 'New_Interaction_2']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "rf_grid_search_1 = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Best hyper-parameters for RandomForestClassifier with top-5 variables: \\n', rf_grid_search_1.best_params_)\n",
    "print('\\nBest score:\\n', rf_grid_search_1.best_score_)\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-6 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', \n",
    "                       'New_Interaction_2', 'valuePerSecond']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "rf_grid_search_2 = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for RandomForestClassifier with top-6 variables: \\n', rf_grid_search_2.best_params_)\n",
    "print('\\nBest score:\\n', rf_grid_search_2.best_score_)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-7 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', \n",
    "                       'New_Interaction_2', 'valuePerSecond', 'New_Interaction_3']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "rf_grid_search_3 = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for RandomForestClassifier with top-7 variables: \\n', rf_grid_search_3.best_params_)\n",
    "print('\\nBest score:\\n', rf_grid_search_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec35d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [ -53.33333333  -60.          -65.          -46.66666667  -46.66666667\n",
      "  -51.66666667  -48.33333333  -55.          -60.          -56.66666667\n",
      "  -60.          -46.66666667           nan           nan           nan\n",
      "  -53.33333333  -60.          -65.          -46.66666667  -43.33333333\n",
      "  -46.66666667  -48.33333333  -65.          -66.66666667  -53.33333333\n",
      "  -53.33333333  -66.66666667           nan           nan           nan\n",
      "  -63.33333333  -73.33333333  -61.66666667  -36.66666667  -25.\n",
      "  -38.33333333  -43.33333333  -46.66666667  -48.33333333  -46.66666667\n",
      "  -40.          -50.                   nan           nan           nan\n",
      "  -70.          -61.66666667  -50.          -41.66666667  -30.\n",
      "  -38.33333333  -43.33333333  -61.66666667  -50.          -48.33333333\n",
      "  -78.33333333  -60.                   nan           nan           nan\n",
      "  -70.          -61.66666667  -50.          -41.66666667  -35.\n",
      "  -38.33333333  -51.66666667  -63.33333333  -61.66666667  -26.66666667\n",
      "  -60.          -58.33333333           nan           nan           nan\n",
      "  -70.          -61.66666667  -50.          -41.66666667  -30.\n",
      "  -38.33333333  -50.          -53.33333333  -56.66666667  -50.\n",
      "  -56.66666667  -58.33333333           nan           nan           nan\n",
      "  -80.          -78.33333333  -71.66666667  -36.66666667  -16.66666667\n",
      "  -31.66666667  -56.66666667  -55.          -55.          -61.66666667\n",
      "  -61.66666667  -53.33333333           nan           nan           nan\n",
      "  -80.          -78.33333333  -71.66666667  -36.66666667  -10.\n",
      "  -31.66666667  -56.66666667  -70.          -65.          -73.33333333\n",
      "  -68.33333333  -63.33333333           nan           nan           nan\n",
      "  -80.          -78.33333333  -71.66666667  -36.66666667  -16.66666667\n",
      "  -33.33333333  -65.          -55.          -75.          -63.33333333\n",
      "  -51.66666667  -71.66666667           nan           nan           nan\n",
      "  -73.33333333  -48.33333333  -50.          -50.          -50.\n",
      "  -78.33333333  -65.          -81.66666667 -153.33333333  -83.33333333\n",
      "  -83.33333333  -63.33333333           nan           nan           nan\n",
      "  -73.33333333  -48.33333333  -36.66666667  -50.          -46.66666667\n",
      "  -73.33333333  -88.33333333  -95.         -101.66666667  -93.33333333\n",
      "  -68.33333333  -70.                   nan           nan           nan\n",
      "  -83.33333333  -50.          -30.          -51.66666667  -46.66666667\n",
      "  -41.66666667  -56.66666667  -61.66666667  -66.66666667  -88.33333333\n",
      "  -46.66666667  -63.33333333           nan           nan           nan\n",
      "  -61.66666667  -20.          -40.          -40.          -65.\n",
      "  -76.66666667  -76.66666667  -48.33333333  -76.66666667  -40.\n",
      "  -65.          -65.                   nan           nan           nan\n",
      "  -61.66666667  -20.          -33.33333333  -40.          -60.\n",
      "  -68.33333333  -51.66666667  -80.          -73.33333333  -63.33333333\n",
      "  -86.66666667  -70.                   nan           nan           nan\n",
      "  -61.66666667  -20.          -43.33333333  -40.          -61.66666667\n",
      "  -58.33333333  -60.          -65.          -90.          -51.66666667\n",
      "  -76.66666667  -63.33333333           nan           nan           nan\n",
      "  -80.          -85.          -25.          -25.          -40.\n",
      "  -43.33333333  -68.33333333  -86.66666667  -98.33333333  -60.\n",
      "  -80.          -55.                   nan           nan           nan\n",
      "  -80.          -85.          -25.          -25.          -36.66666667\n",
      "  -53.33333333  -63.33333333 -101.66666667  -98.33333333  -73.33333333\n",
      "  -66.66666667  -53.33333333           nan           nan           nan\n",
      "  -80.          -85.          -25.          -16.66666667  -36.66666667\n",
      "  -46.66666667  -73.33333333  -93.33333333 -108.33333333  -70.\n",
      "  -61.66666667  -60.                   nan           nan           nan\n",
      "  -36.66666667  -65.          -41.66666667  -58.33333333  -61.66666667\n",
      "  -83.33333333 -116.66666667 -110.         -108.33333333  -75.\n",
      "  -61.66666667  -60.                   nan           nan           nan\n",
      "  -36.66666667  -65.          -41.66666667  -60.          -58.33333333\n",
      "  -93.33333333  -93.33333333 -103.33333333 -116.66666667  -61.66666667\n",
      "  -46.66666667  -60.                   nan           nan           nan\n",
      "  -46.66666667  -26.66666667  -33.33333333  -58.33333333  -63.33333333\n",
      "  -76.66666667  -85.         -103.33333333 -113.33333333  -78.33333333\n",
      "  -46.66666667  -53.33333333           nan           nan           nan\n",
      "  -28.33333333  -21.66666667  -46.66666667  -38.33333333  -86.66666667\n",
      "  -73.33333333  -90.         -121.66666667 -118.33333333  -86.66666667\n",
      "  -81.66666667  -55.                   nan           nan           nan\n",
      "  -28.33333333  -21.66666667  -46.66666667  -41.66666667  -90.\n",
      "  -75.          -85.         -146.66666667 -123.33333333  -86.66666667\n",
      "  -71.66666667  -70.                   nan           nan           nan\n",
      "  -28.33333333  -21.66666667  -41.66666667  -41.66666667  -83.33333333\n",
      "  -86.66666667  -95.         -125.         -135.         -120.\n",
      "  -91.66666667  -68.33333333           nan           nan           nan\n",
      "  -85.          -30.          -16.66666667  -26.66666667  -58.33333333\n",
      "  -58.33333333  -78.33333333 -106.66666667 -120.          -58.33333333\n",
      "  -60.          -66.66666667           nan           nan           nan\n",
      "  -85.          -30.          -16.66666667  -25.          -58.33333333\n",
      "  -58.33333333  -71.66666667  -86.66666667  -98.33333333  -71.66666667\n",
      "  -75.          -56.66666667           nan           nan           nan\n",
      "  -85.          -30.          -16.66666667  -25.          -58.33333333\n",
      "  -63.33333333  -78.33333333 -100.         -100.          -71.66666667\n",
      "  -70.          -48.33333333           nan           nan           nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters for AdaBoostClassifier with top-5 variables: \n",
      " {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 15, 'base_estimator__min_samples_split': 10, 'learning_rate': 0.01, 'n_estimators': 300}\n",
      "\n",
      "Best score:\n",
      " -10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [ -56.66666667  -76.66666667  -56.66666667  -20.          -30.\n",
      "  -16.66666667  -23.33333333  -21.66666667  -38.33333333  -36.66666667\n",
      "  -25.          -15.                   nan           nan           nan\n",
      "  -56.66666667  -76.66666667  -56.66666667  -20.          -35.\n",
      "  -31.66666667  -23.33333333  -16.66666667  -28.33333333  -13.33333333\n",
      "  -31.66666667  -38.33333333           nan           nan           nan\n",
      "  -80.          -70.          -71.66666667  -28.33333333  -18.33333333\n",
      "  -15.          -38.33333333  -36.66666667  -26.66666667  -26.66666667\n",
      "  -33.33333333  -25.                   nan           nan           nan\n",
      "  -70.          -61.66666667  -66.66666667  -51.66666667  -23.33333333\n",
      "  -31.66666667  -28.33333333  -35.          -25.          -41.66666667\n",
      "  -35.          -45.                   nan           nan           nan\n",
      "  -70.          -61.66666667  -66.66666667  -56.66666667  -23.33333333\n",
      "  -31.66666667  -28.33333333  -31.66666667  -41.66666667  -38.33333333\n",
      "  -35.          -40.                   nan           nan           nan\n",
      "  -70.          -61.66666667  -66.66666667  -51.66666667  -23.33333333\n",
      "  -31.66666667  -28.33333333  -31.66666667  -25.          -15.\n",
      "  -43.33333333  -48.33333333           nan           nan           nan\n",
      "  -80.          -78.33333333  -80.          -45.          -20.\n",
      "  -16.66666667  -43.33333333  -25.          -40.          -41.66666667\n",
      "  -31.66666667  -35.                   nan           nan           nan\n",
      "  -80.          -78.33333333  -80.          -45.          -26.66666667\n",
      "  -26.66666667  -45.          -51.66666667  -45.          -76.66666667\n",
      "  -50.          -45.                   nan           nan           nan\n",
      "  -80.          -78.33333333  -80.          -45.          -26.66666667\n",
      "  -26.66666667  -45.          -51.66666667  -46.66666667  -55.\n",
      "  -40.          -36.66666667           nan           nan           nan\n",
      "  -48.33333333  -28.33333333  -35.          -25.          -33.33333333\n",
      "  -31.66666667  -18.33333333  -28.33333333  -53.33333333  -20.\n",
      "  -41.66666667  -36.66666667           nan           nan           nan\n",
      "  -48.33333333  -33.33333333  -35.          -18.33333333  -40.\n",
      "  -21.66666667  -35.          -23.33333333  -58.33333333  -35.\n",
      "  -33.33333333  -25.                   nan           nan           nan\n",
      "  -76.66666667  -36.66666667  -15.          -33.33333333  -26.66666667\n",
      "  -40.          -23.33333333  -40.          -31.66666667  -21.66666667\n",
      "    1.66666667  -25.                   nan           nan           nan\n",
      "  -61.66666667  -58.33333333  -46.66666667  -45.          -50.\n",
      "  -56.66666667  -35.          -36.66666667  -40.          -28.33333333\n",
      "  -33.33333333  -35.                   nan           nan           nan\n",
      "  -61.66666667  -58.33333333  -46.66666667  -45.          -46.66666667\n",
      "  -43.33333333  -43.33333333  -53.33333333  -58.33333333  -10.\n",
      "  -51.66666667  -36.66666667           nan           nan           nan\n",
      "  -61.66666667  -58.33333333  -46.66666667  -36.66666667  -56.66666667\n",
      "  -56.66666667  -45.          -40.          -53.33333333  -46.66666667\n",
      "  -26.66666667  -33.33333333           nan           nan           nan\n",
      "  -81.66666667  -68.33333333  -33.33333333  -31.66666667  -43.33333333\n",
      "  -40.          -35.          -48.33333333  -31.66666667  -33.33333333\n",
      "  -40.          -35.                   nan           nan           nan\n",
      "  -81.66666667  -68.33333333  -33.33333333  -28.33333333  -46.66666667\n",
      "  -43.33333333  -51.66666667  -43.33333333  -38.33333333  -31.66666667\n",
      "  -31.66666667  -35.                   nan           nan           nan\n",
      "  -81.66666667  -68.33333333  -33.33333333  -28.33333333  -43.33333333\n",
      "  -50.          -45.          -25.          -40.          -40.\n",
      "  -41.66666667  -41.66666667           nan           nan           nan\n",
      "  -68.33333333  -33.33333333  -33.33333333  -36.66666667  -45.\n",
      "  -63.33333333  -53.33333333  -91.66666667  -56.66666667  -30.\n",
      "  -28.33333333  -30.                   nan           nan           nan\n",
      "  -68.33333333  -41.66666667  -33.33333333  -41.66666667  -41.66666667\n",
      "  -61.66666667  -41.66666667  -31.66666667  -78.33333333  -10.\n",
      "   -6.66666667  -31.66666667           nan           nan           nan\n",
      "  -60.          -43.33333333  -41.66666667  -31.66666667  -51.66666667\n",
      "  -25.          -43.33333333  -78.33333333  -56.66666667  -20.\n",
      "  -28.33333333  -25.                   nan           nan           nan\n",
      "  -40.          -18.33333333   -3.33333333  -38.33333333  -66.66666667\n",
      "  -81.66666667  -80.          -71.66666667  -53.33333333  -41.66666667\n",
      "  -23.33333333  -18.33333333           nan           nan           nan\n",
      "  -40.          -18.33333333   -5.          -45.          -55.\n",
      "  -73.33333333  -68.33333333  -68.33333333  -95.          -38.33333333\n",
      "  -21.66666667  -31.66666667           nan           nan           nan\n",
      "  -40.          -15.           -3.33333333  -45.          -68.33333333\n",
      "  -76.66666667  -61.66666667  -86.66666667  -85.          -41.66666667\n",
      "  -21.66666667  -33.33333333           nan           nan           nan\n",
      "  -91.66666667  -38.33333333  -15.          -33.33333333  -36.66666667\n",
      "  -31.66666667  -56.66666667  -45.         -121.66666667  -26.66666667\n",
      "  -35.          -33.33333333           nan           nan           nan\n",
      "  -91.66666667  -38.33333333  -15.          -25.          -41.66666667\n",
      "  -35.          -58.33333333  -28.33333333  -78.33333333  -58.33333333\n",
      "  -40.          -18.33333333           nan           nan           nan\n",
      "  -91.66666667  -38.33333333  -15.          -33.33333333  -41.66666667\n",
      "  -36.66666667  -50.          -83.33333333  -66.66666667  -65.\n",
      "  -30.          -23.33333333           nan           nan           nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyper-parameters for AdaBoostClassifier with top-6 variables: \n",
      " {'base_estimator__max_depth': 5, 'base_estimator__min_samples_leaf': 5, 'base_estimator__min_samples_split': 15, 'learning_rate': 1, 'n_estimators': 300}\n",
      "\n",
      "Best score:\n",
      " 1.6666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [ -60.          -61.66666667  -45.          -21.66666667   -1.66666667\n",
      "  -30.          -26.66666667  -31.66666667  -35.          -35.\n",
      "  -46.66666667  -18.33333333           nan           nan           nan\n",
      "  -60.          -61.66666667  -45.          -21.66666667   -1.66666667\n",
      "  -13.33333333  -26.66666667  -36.66666667  -41.66666667  -13.33333333\n",
      "  -38.33333333  -36.66666667           nan           nan           nan\n",
      "  -58.33333333  -68.33333333  -68.33333333  -26.66666667  -21.66666667\n",
      "  -11.66666667   -8.33333333  -36.66666667  -26.66666667  -20.\n",
      "  -21.66666667  -38.33333333           nan           nan           nan\n",
      "  -88.33333333  -65.          -75.          -31.66666667  -31.66666667\n",
      "  -25.          -30.          -21.66666667  -33.33333333  -33.33333333\n",
      "  -26.66666667  -25.                   nan           nan           nan\n",
      "  -88.33333333  -65.          -75.          -31.66666667  -31.66666667\n",
      "  -26.66666667  -30.          -33.33333333  -31.66666667  -31.66666667\n",
      "  -41.66666667  -38.33333333           nan           nan           nan\n",
      "  -88.33333333  -65.          -75.          -25.          -25.\n",
      "  -26.66666667  -28.33333333  -26.66666667  -33.33333333  -40.\n",
      "  -31.66666667  -28.33333333           nan           nan           nan\n",
      "  -88.33333333  -81.66666667  -91.66666667  -40.           -8.33333333\n",
      "  -10.          -56.66666667  -43.33333333  -36.66666667  -46.66666667\n",
      "  -40.          -43.33333333           nan           nan           nan\n",
      "  -88.33333333  -81.66666667  -91.66666667  -40.           -8.33333333\n",
      "   -5.          -55.          -53.33333333  -38.33333333  -16.66666667\n",
      "  -43.33333333  -48.33333333           nan           nan           nan\n",
      "  -88.33333333  -81.66666667  -91.66666667  -40.           -8.33333333\n",
      "  -10.          -56.66666667  -31.66666667  -45.           -3.33333333\n",
      "  -43.33333333  -38.33333333           nan           nan           nan\n",
      "  -56.66666667  -11.66666667  -38.33333333  -13.33333333  -36.66666667\n",
      "  -16.66666667  -18.33333333  -51.66666667  -40.          -35.\n",
      "  -23.33333333  -18.33333333           nan           nan           nan\n",
      "  -56.66666667  -11.66666667  -38.33333333  -36.66666667  -35.\n",
      "  -16.66666667  -33.33333333  -28.33333333  -43.33333333  -40.\n",
      "  -13.33333333   -5.                   nan           nan           nan\n",
      "  -70.          -20.          -26.66666667  -11.66666667  -28.33333333\n",
      "  -30.            5.          -56.66666667  -41.66666667  -38.33333333\n",
      "   -8.33333333  -13.33333333           nan           nan           nan\n",
      "  -68.33333333  -33.33333333  -45.          -48.33333333  -33.33333333\n",
      "  -11.66666667  -38.33333333  -46.66666667  -33.33333333  -40.\n",
      "  -23.33333333  -35.                   nan           nan           nan\n",
      "  -68.33333333  -33.33333333  -45.          -50.          -21.66666667\n",
      "  -10.          -38.33333333  -36.66666667  -50.          -43.33333333\n",
      "  -35.          -31.66666667           nan           nan           nan\n",
      "  -68.33333333  -33.33333333  -45.          -51.66666667  -26.66666667\n",
      "  -23.33333333  -30.          -58.33333333  -51.66666667  -40.\n",
      "  -28.33333333  -38.33333333           nan           nan           nan\n",
      "  -61.66666667  -61.66666667  -21.66666667  -43.33333333  -28.33333333\n",
      "  -23.33333333  -46.66666667  -55.          -46.66666667  -21.66666667\n",
      "  -46.66666667  -61.66666667           nan           nan           nan\n",
      "  -61.66666667  -61.66666667  -21.66666667  -43.33333333  -28.33333333\n",
      "  -26.66666667  -46.66666667  -28.33333333  -53.33333333  -51.66666667\n",
      "  -51.66666667  -41.66666667           nan           nan           nan\n",
      "  -61.66666667  -61.66666667  -21.66666667  -40.          -28.33333333\n",
      "  -31.66666667  -63.33333333  -45.          -48.33333333  -53.33333333\n",
      "  -35.          -41.66666667           nan           nan           nan\n",
      "  -40.          -30.          -25.          -45.          -38.33333333\n",
      "  -50.          -48.33333333  -36.66666667  -73.33333333  -11.66666667\n",
      "  -31.66666667  -23.33333333           nan           nan           nan\n",
      "  -31.66666667  -20.          -21.66666667  -48.33333333  -51.66666667\n",
      "  -53.33333333  -28.33333333  -46.66666667  -56.66666667  -33.33333333\n",
      "  -33.33333333  -23.33333333           nan           nan           nan\n",
      "  -50.          -15.          -33.33333333  -30.          -55.\n",
      "  -51.66666667  -65.          -60.          -71.66666667  -46.66666667\n",
      "  -41.66666667  -31.66666667           nan           nan           nan\n",
      "  -30.          -38.33333333  -16.66666667  -48.33333333  -70.\n",
      "  -68.33333333  -83.33333333  -76.66666667  -70.          -33.33333333\n",
      "  -21.66666667  -30.                   nan           nan           nan\n",
      "  -38.33333333  -38.33333333  -26.66666667  -43.33333333  -65.\n",
      "  -65.         -100.          -98.33333333  -78.33333333  -26.66666667\n",
      "  -16.66666667  -33.33333333           nan           nan           nan\n",
      "  -38.33333333  -38.33333333  -13.33333333  -55.          -65.\n",
      "  -81.66666667  -68.33333333  -53.33333333  -78.33333333   -6.66666667\n",
      "  -36.66666667  -25.                   nan           nan           nan\n",
      "  -70.          -26.66666667   -5.          -25.          -26.66666667\n",
      "  -53.33333333  -63.33333333  -63.33333333  -73.33333333  -23.33333333\n",
      "  -61.66666667  -40.                   nan           nan           nan\n",
      "  -70.          -26.66666667   -5.          -35.          -41.66666667\n",
      "  -25.          -60.          -63.33333333  -91.66666667  -41.66666667\n",
      "  -28.33333333  -31.66666667           nan           nan           nan\n",
      "  -70.          -26.66666667   -5.          -28.33333333  -23.33333333\n",
      "  -23.33333333  -56.66666667 -106.66666667  -80.          -48.33333333\n",
      "  -30.          -31.66666667           nan           nan           nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyper-parameters for AdaBoostClassifier with top-7 variables: \n",
      " {'base_estimator__max_depth': 5, 'base_estimator__min_samples_leaf': 5, 'base_estimator__min_samples_split': 15, 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "\n",
      "Best score:\n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "## ii) Model: AdaBoostClassifier\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "ada_param_grid = {'n_estimators': [100, 300, 500], 'base_estimator__min_samples_split': [5, 10, 15], \n",
    "                  'base_estimator__min_samples_leaf': [5, 10, 15], 'base_estimator__max_depth': [3, 5, 7], \n",
    "                  'learning_rate': [0.001, 0.01, 0.1, 1, 100]}\n",
    "\n",
    "## Defining the custom scorer\n",
    "my_scorer = make_scorer(dmc_cost_function.cost_function, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-5 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', 'New_Interaction_2']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "ada_grid_search_1 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_param_grid, \n",
    "                                 cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Best hyper-parameters for AdaBoostClassifier with top-5 variables: \\n', ada_grid_search_1.best_params_)\n",
    "print('\\nBest score:\\n', ada_grid_search_1.best_score_)\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-6 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', \n",
    "                       'New_Interaction_2', 'valuePerSecond']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "ada_grid_search_2 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_param_grid, \n",
    "                                 cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for AdaBoostClassifier with top-6 variables: \\n', ada_grid_search_2.best_params_)\n",
    "print('\\nBest score:\\n', ada_grid_search_2.best_score_)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-7 variables\n",
    "X_train_sub = X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', \n",
    "                       'New_Interaction_2', 'valuePerSecond', 'New_Interaction_3']]\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "ada_grid_search_3 = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_param_grid, \n",
    "                                 cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for AdaBoostClassifier with top-7 variables: \\n', ada_grid_search_3.best_params_)\n",
    "print('\\nBest score:\\n', ada_grid_search_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a119c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters for AdaBoostClassifier with top-5 variables: \n",
      " {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      "Best score:\n",
      " -86.66666666666667\n",
      "\n",
      "Best hyper-parameters for AdaBoostClassifier with top-6 variables: \n",
      " {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      "Best score:\n",
      " -81.66666666666667\n",
      "\n",
      "Best hyper-parameters for AdaBoostClassifier with top-7 variables: \n",
      " {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n",
      "\n",
      "Best score:\n",
      " -81.66666666666667\n"
     ]
    }
   ],
   "source": [
    "## iii) Model: Support Vector Classifier\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "svc_param_grid = {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.01, 0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "## Defining the custom scorer\n",
    "my_scorer = make_scorer(dmc_cost_function.cost_function, greater_is_better = True, needs_proba = True)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-5 variables\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "X_train_sub = scaler.fit_transform(X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', 'totalScanTimeInSeconds', 'New_Interaction_2']])\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "svc_grid_search_1 = GridSearchCV(SVC(probability = True), svc_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('Best hyper-parameters for AdaBoostClassifier with top-5 variables: \\n', svc_grid_search_1.best_params_)\n",
    "print('\\nBest score:\\n', svc_grid_search_1.best_score_)\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-6 variables\n",
    "X_train_sub = scaler.fit_transform(X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', \n",
    "                                            'totalScanTimeInSeconds', 'New_Interaction_2', 'valuePerSecond']])\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "svc_grid_search_2 = GridSearchCV(SVC(probability = True), svc_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for AdaBoostClassifier with top-6 variables: \\n', svc_grid_search_2.best_params_)\n",
    "print('\\nBest score:\\n', svc_grid_search_2.best_score_)\n",
    "\n",
    "\n",
    "## -------------------------------\n",
    "\n",
    "## Selecting the top-7 variables\n",
    "X_train_sub = scaler.fit_transform(X_train[['trustLevel', 'New_Interaction_1', 'Heredity_Feature_3', \n",
    "                                            'totalScanTimeInSeconds', 'New_Interaction_2', 'valuePerSecond', 'New_Interaction_3']])\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "svc_grid_search_3 = GridSearchCV(SVC(probability = True), svc_param_grid, cv = 3, scoring = my_scorer, n_jobs = -1).fit(X_train_sub, Y_train)\n",
    "\n",
    "## Extracting the best hyper-parameters\n",
    "print('\\nBest hyper-parameters for AdaBoostClassifier with top-7 variables: \\n', svc_grid_search_3.best_params_)\n",
    "print('\\nBest score:\\n', svc_grid_search_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From all of the above considered models, we see the best performance from the ______ model with the top-____ input variables and ______\n",
    "## as hyper-parameters. This model has the highest cost function score across the grid search cross-validation process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
